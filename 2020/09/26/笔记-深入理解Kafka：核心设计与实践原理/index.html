<!DOCTYPE HTML>
<html>

<head>
    <script>
        var timeStart = new Date();
    </script>
    <meta charset="utf-8">
    
    <title>[笔记]-深入理解Kafka：核心设计与实践原理 | 草木禾</title>
    
    <meta name="author" content="huangzhike">
    
    
    <meta name="description"
        content="基于《深入理解Kafka：核心设计与实践原理》朱忠华 著整理的读书笔记，基于2.0.0，目前最新的Release是2.6.0。
作者也有博客，有兴趣可以看看（NSFW警告）。
看这本书的目的是了解Kafka基本的设计和思想，太细节的东西有机会再了解吧（估计没有）。
之前没用过Kafka，感觉和火箭还">
    
    
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta property="og:title" content="[笔记]-深入理解Kafka：核心设计与实践原理" />
    
    <meta property="og:site_name" content="草木禾" />
    
    
    <!-- favicon -->
    <link rel="icon" type="image/ico" href="/logo.ico" sizes="32x32">
    <meta name="msapplication-TileColor" content="#009688">
    <meta name="msapplication-TileImage" content="/mstile-144x144.ico">
    <meta name="theme-color" content="#009688">
    <!-- favicon end -->
    <!-- <link href="//ok.ico" rel="icon"> -->
    

    <!-- <link href="https://cdn.bootcdn.net/ajax/libs/twitter-bootstrap/4.5.0/css/bootstrap.min.css" rel="stylesheet"> -->
    <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
    <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
    <link rel="stylesheet" href="/css/prism.css" media="screen" type="text/css">

<meta name="generator" content="Hexo 4.2.1"></head>
<body>
    <nav class="navbar navbar-default">
	<div class="container">
		<div class="navbar-header">
			<button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false" aria-controls="navbar">
				<span class="sr-only">菜单</span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
				<span class="icon-bar"></span>
			</button>
			<a class="navbar-brand" title="早く来い、クラウド" href="/">Reunion...</a>
           
		</div>
		<div id="navbar" class="collapse navbar-collapse">
			<ul class="nav navbar-nav navbar-right">
				
				<li>
					<a href="https://huangzhike.github.io/archives" title="">
						<i class="fa fa-list"></i>Archives
					</a>
				</li>
				
				<li>
					<a href="https://github.com/huangzhike" target="_blank" rel="noopener" title="">
						<i class="fa fa-github"></i>GitHub
					</a>
				</li>
				
			</ul>
		</div>
	</div>
</nav>

    <div class="container" >
        <div class="row">
	
		<div class="col-md-9 center-content">
			
			<div class="content">
				<!-- index -->
				
				<h2>[笔记]-深入理解Kafka：核心设计与实践原理</h2>
				
				<div>
					<div class="post-time">2020-09-26</div>
				</div>
				
				<div class="article-content">
				<p>基于<strong><a href="https://book.douban.com/subject/30437872/" target="_blank" rel="noopener">《深入理解Kafka：核心设计与实践原理》朱忠华 著</a></strong>整理的读书笔记，基于2.0.0，目前最新的Release是2.6.0。</p>
<p>作者也有<a href="https://honeypps.com/about/me/" target="_blank" rel="noopener">博客</a>，有兴趣可以看看（NSFW警告）。</p>
<p>看这本书的目的是了解Kafka基本的设计和思想，太细节的东西有机会再了解吧（<del>估计没有</del>）。</p>
<p>之前没用过Kafka，感觉和火箭还是有很多类似的，不过比火箭复杂多了，还引入了ZooKeeper进行分布式协调。</p>
<hr>
<p>Kafka包括若干Producer、若干Broker、若干Consumer，以及一个ZooKeeper集群。</p>
<p>主题（Topic）：消息以Topic为单位归类，Producer将消息发送到Topic，Consumer订阅Topic并消费。</p>
<p>分区（Partition）：Topic分多个分区，消息顺序追加到分区日志文件尾部，偏移量保证消息在分区内的顺序性。</p>
<p>Topic的分区可以分布在不同的Broker上，通过增加分区数量实现水平扩展。</p>
<p>分区引入了多副本（Replica）机制，通过增加副本数量提升容灾能力。</p>
<p>副本之间是一主多从，只有Leader副本处理读写请求，Follower副本只与Leader副本同步消息。</p>
<p>分区的副本分布在不同的Broker上，Leader副本故障时，从Follower副本中选举新的Leader副本对外服务。</p>
<ul>
<li><p>本地副本（Local Replica）：指对应的日志在当前Broker上。</p>
</li>
<li><p>远程副本（Remote Replica）：指对应的日志在其他Broker上。</p>
</li>
</ul>
<p>一个分区的信息保存在多个Broker上，逻辑上每个Broker上的分区有多个副本，但是只有本地副本才有对应的日志。</p>
<p>假设Kafka集群有4个Broker，某个Topic中有3个分区，且副本因子（即副本个数）也为3，每个分区便有1个Leader副本和2个Follower副本。</p>
<p>LEO（Log End Offset）：标识每个分区中最后一条消息的下一个位置，分区的每个副本都有自己的LEO。</p>
<p>HW（High Watermark）：高水位，ISR集合中最小的LEO，Consumer只能拉取到HW之前的消息。</p>
<p>消息先会被写入分区的Leader副本，等待ISR集合中所有Follower副本都同步完后才认为已提交，然后更新分区的HW，Consumer才可以消费。</p>
<p>分区HW就是Leader副本的HW值。</p>
<p>LW（Low Watermark）：低水位，AR集合中最小的logStartOffset，日志被清理可能促使LW的增长。</p>
<p>分区中的所有副本统称为AR（Assigned Replicas）。</p>
<p>所有与Leader副本保持一定程度同步的副本（包括Leader副本）组成ISR（In-Sync Replicas）。</p>
<p>当ISR集合中Follower副本滞后Leader副本的时间超过阈值，判定副本失效，从ISR剔除。</p>
<p>Follower副本赶上Leader副本的LEO时，则认为该Follower副本已经追赶上Leader副本，此时更新该副本的lastCaughtUpTimeMs。</p>
<p>Follower副本拉取Leader副本不会更新lastCaughtUpTimeMs，因为Leader副本的消息流入速度可能大于Follower副本的拉取速度。</p>
<p>Leader副本负责维护ISR集合中所有Follower副本的状态，当Follower副本失效时，Leader副本把它从ISR中剔除。</p>
<p>如果OSR集合中有Follower副本追上了Leader副本，Leader副本会把它从OSR集合转移至ISR集合。</p>
<p>一般两种情况会导致副本失效：</p>
<ul>
<li><p>Follower副本进程挂起（如Full GC），超时没有向Leader副本发起同步请求。</p>
</li>
<li><p>Follower副本进程同步过慢，如IO开销过大。</p>
</li>
</ul>
<p>Leader副本故障时，默认只有在ISR集合中的副本才有资格被选举为新的Leader副本。</p>
<p>Kafka会开启两个与ISR相关的定时任务。</p>
<p>定时检查当前时间与副本的lastCaughtUpTimeMs差值，是否需要增减ISR集合，将变更后的记录缓存到isrChangeSet。</p>
<p>定时检查isrChangeSet，如果有变更记录，那么在ZooKeeper的指定路径下创建一个持久节点，并将isrChangeSet中的信息保存到节点。</p>
<p>Kafka控制器添加了Watcher，当这个节点有子节点变化时触发，通知控制器更新相关元数据井向Broker节点发送更新元数据请求。</p>
<p>分区提供了可伸缩性、水平扩展的功能，多副本提供数据冗余以提高数据可靠性。</p>
<hr>
<p>Kafka的复制不是完全的同步或异步复制。</p>
<p>同步复制时，所有Follower副本都复制完，才会被确认为成功提交，极大地影响了性能。</p>
<p>异步复制时，只要Leader副本写入就认为成功提交，Follower副本异步地从Leader副本复制数据。</p>
<p>如果Follower副本还没有复制完，Leader副本突然宕机，则会造成数据丢失。</p>
<p>Kafka的ISR则权衡了可靠性和性能之间的关系。</p>
<p>日志同步机制的一个原则是：如果告知客户端已经成功提交了某条消息，即使Leader宕机，也要保证新选举出来的Leader包含这条消息。</p>
<p>常见的做法是“少数服从多数”，如果有2n + 1个副本，那么必须保证有n + 1个副本同步完消息。</p>
<p>为了保证较高的容错率，必须要有大量的副本，而大量副本又会在大数据量下性能下降。</p>
<p>Kafka使用类似微软的PacificA算法，位于ISR中的任何副本节点都有资格成为Leader，选举简单、开销低。</p>
<p>在采用ISR模型和n + 1个副本数的配置下，一个Kafka分区最大能够容忍n个节点失败。</p>
<p>因为慢的都被踢走了:)。</p>
<hr>
<p>Leader副本收到消息，更新本地日志和LEO和HW。</p>
<p>Follower副本不断向Leader副本发送FETCH请求，收到响应后更新本地日志和LEO和HW。</p>
<p>Follower副本更新本地HW是在更新本地LEO后，取本地LEO与FETCH响应中HW值的较小值。</p>
<p>Leader副本保存了所有副本的LEO，用来确定分区的HW。</p>
<p>Follower副本发送FETCH请求时，携带了本次的拉取偏移，Leader副本根据此偏移更新该副本的LEO。</p>
<p>Leader副本的HW值就是分区的HW值，以下情况Kafka会尝试更新Leader副本的HW值：</p>
<ol>
<li><p>副本成为Leader副本时；</p>
</li>
<li><p>副本被踢出ISR时，需要执行ISR的缩减；</p>
</li>
<li><p>向Leader副本写入消息时，更新Leader副本的LEO；</p>
</li>
<li><p>Leader副本处理Follower副本FETCH请求时；</p>
</li>
</ol>
<hr>
<p>分区HW值的更新通常需要延迟一轮FETCH才能完成，可能引起：分区数据丢失，分区数据不一致。</p>
<ul>
<li>数据丢失：</li>
</ul>
<p>假设Producer的min.insync.replicas为1，并且有两个副本，A是Leader副本。</p>
<p>消息写入A和B副本的Log，分区HW已被更新，响应写入成功。</p>
<p>假设此时B，即Follower副本的HW尚未更新（延迟了一轮），然后B宕机，重启后B会把LEO调整到HW值，截断日志。</p>
<p>假设B重启后，A也宕机了，那么B成为新的Leader副本，消息丢失了。</p>
<ul>
<li>数据不一致：</li>
</ul>
<p>假设Producer的min.insync.replicas为1，并且有两个副本，A是Leader副本，B被踢出了ISR。</p>
<p>A的Log写入了1条消息，分区HW更新到1，B的Log没写入消息，B的HW还是0。</p>
<p>假设A和B同时宕机，然后B先重启成为Leader，分区HW = 0。</p>
<p>假设此时Producer又发了消息给B，于是B的Log写入1条消息，分区HW更新到1（就B一个副本，直接更新HW）。</p>
<p>之后A重启，执行日志截断，发现此时分区HW = 1，而A之前的HW值也是1，故不做调整。</p>
<p>此时两个副本Log的第一条消息不一致。</p>
<p>Kafka引入了Leader Epoch。</p>
<p>Leader的内存缓存了Leader的Epoch信息，实际上是一对值：（Epoch，Offset）。</p>
<p>Epoch表示Leader的版本号，而Offset对应于该Epoch版本的Leader写入第一条消息的位移。</p>
<p>假设有两对值：(0, 0)和(1, 120)，则表示第一个Leader从位移0开始写入消息，共写了120条[0, 119]；而第二个Leader版本号是1，从位移120处开始写入消息。</p>
<p>Leader维护这个缓存，并定期持久化。</p>
<p>恢复时使用这些信息而非HW来判断是否需要截断日志。</p>
<p>当前A为Leader，B为Follower，A中有2条消息m1和m2，B中有1条消息m1。</p>
<p>假设A和B同时宕机，然后B第一个恢复并成为新的Leader。</p>
<p>之后B写入消息m3，并将LEO和HW更新至2，此时Leader Epoch从0增至1。</p>
<p>接着A恢复成为Follower，并向B发送OffsetsForLeaderEpochRequest请求，此时A的Leader Epoch为0。</p>
<p>A根据返回的结果截断日志，删除了消息m2，之后A发送FetchRequest至B请求同步数据，最终A和B中都有两条消息m1和m3，HW和LEO都为2，并且Leader Epoch都为1，解决了数据不一致。</p>
<hr>
<p>Kafka是主写主读的模型。</p>
<p>主写从读，也就是读写分离，Kafka不支持主写从读。</p>
<p>主写从读，让从节点分担主节点的负载，但也有两个明显缺点：</p>
<p>在主从节点数据复制延时的时间窗口内，存在数据一致性问题。</p>
<p>一是延时，一是数据一致性。</p>
<p>主读从写不能做到完全的负载均衡，如写压力很大而读压力很小的情况。</p>
<p>Kafka中可以在主写主读的架构上实现负载均衡（分区），所以没必要支持主写从读。</p>
<hr>
<p>Topic和分区都是逻辑上的概念，分区可以有多个副本，每个副本对应一个日志文件。</p>
<p>每个日志文件对应多个日志分段（LogSegment），每个日志分段还可以分为索引文件、日志存储文件和快照文件等。</p>
<p>可以通过日志文件的根目录来查看集群中各个Broker的分区副本的分配情况，还可以通过ZooKeeper获取。</p>
<p>创建Topic时会在ZooKeeper特定目录下创建节点，记录该Topic的分区副本分配方案。</p>
<p>创建Topic时，分区及副本会尽可能均匀地分布到各个Broker，一个分区的副本不可能同时存在于一个Broker中。</p>
<p>Leader副本所在的Broker节点叫作分区的Leader节点，Follower副本所在的Broker节点叫作分区的Follower节点。</p>
<p>当Leader副本故障时（原本的节点失效了，导致负载不均衡），Follower副本成为新的Leader副本。</p>
<p>为了治理负载失衡，Kafka引入了优先副本（Preferred Replica），优先副本是指在AR集合中的第一个副本。</p>
<p>理想情况下，优先副本就是该分区的Leader副本，只要确保优先副本在集群中均匀分布，就保证了所有分区的Leader均衡分布。</p>
<p>Leader副本的选举由KafkaController负责。</p>
<p>当创建分区（创建Topic或增加分区）或分区上线（分区中原先的Leader副本下线，需要选举新的Leader上线）时都要执行Leader选举。</p>
<p>基本思路是按照AR集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。</p>
<p>只要不发生重分配，分区的AR集合内部副本的顺序是不变的，而分区的ISR集合中副本的顺序可能改变。</p>
<p>注意这里是根据AR的顺序而不是ISR的顺序进行选举的。</p>
<p>Kafka默认分区自动平衡，KafkaController启动定时任务，轮询所有的Broker节点，计算每个Broker节点的分区不平衡率（非优先副本的Leader数／分区总数）是否超过阈值，超过则自动执行优先副本的选举。</p>
<p>生产环境中建议关闭，因为执行时机不可控，分区在Leader切换过程中不可用，建议手动执行分区平衡。</p>
<p>并且分区及副本的均衡也不能完全确保整体的均衡。</p>
<p>下线集群中的节点时，希望能够将该节点上的分区副本迁移到其他的节点上。</p>
<p>新增集群中的节点后，只有新创建的Topic分区才被分配到这个节点上，之前的Topic分区不会自动分配到新节点中。</p>
<p>分区重分配：KafkaController为分区添加新副本（增加副本因子），新的副本从Leader副本复制数据，复制完成后，KafkaController将旧副本从副本清单里移除（恢复为原先的副本因子）。</p>
<p>分区重分配本质：数据复制，先增加新的副本，然后进行数据同步，最后删除旧的副本。</p>
<hr>
<p>理论上分区数越多，吞吐量越大，但分区数一直增加可能会引起Kafka进程的崩溃。</p>
<p>分区数会占用文件描述符，而一个进程所能支配的文件描述符是有限的，“Too many open flies”。</p>
<p>一般建议将分区数设定为集群中Broker的倍数，假定集群中有3个Broker节点，可以设定分区数为3、6、9等。</p>
<p>假如一个3节点的Kafka集群中存在3000个分区，每个分区拥有3个数据副本。</p>
<p>一个Broker宕机时，它的所有1000个分区同时变得不可用。</p>
<p>假设一个分区恢复时间是5ms，1000个分区的恢复将花费5s，系统不可用时间会明显变长。</p>
<p>而且分区太多，整体上就是随机读写，会造成系统性能下降。</p>
<hr>
<p>不考虑副本，一个分区对应一个日志（Log）。</p>
<p>为了防止Log过大，Log分为多个LogSegment。</p>
<p>Log对应文件夹，LogSegment对应一个日志文件和两个索引文件等。</p>
<p>消息顺序写入Log，只有最后一个LogSegment才能写入。</p>
<p>每个LogSegment的.log文件都有对应的两个索引文件：偏移量索引.index文件和时间戳索引.timeindex文件。</p>
<p>每个LogSegment都有一个基准偏移量baseOffset，表示当前LogSegment中第一条消息的偏移（可以理解为下标）。</p>
<p>偏移量是个64位的长整型，文件根据基准偏移量命名。</p>
<p>索引文件是稀疏索引，不是每个消息都有对应的索引，而是每写入一定量时才生成。</p>
<p>稀疏索引是在磁盘空间、内存空间、查找时间之间的折中。</p>
<p>稀疏索引体积较小，通过MappedByteBuffer映射到内存中，加快索引的查询速度。</p>
<p>偏移量索引文件中，每个索引项分为两个部分：</p>
<ul>
<li><p>relativeOffset：相对偏移量，消息相对于baseOffset的位置偏移量，目的是减少空间占用。</p>
</li>
<li><p>position：物理地址，消息在分段文件中对应的物理位置。</p>
</li>
</ul>
<p>如果要查找偏移量offset为268的消息：</p>
<ol>
<li>定位分段文件：</li>
</ol>
<p>Kafka使用跳表ConcurrentSkipListMap保存日志分段，每个日志分段的baseOffset为key.</p>
<p>以基准偏移量排序，根据二分查找定位到最大的小于offset的日志分段。</p>
<ol start="2">
<li>定位消息位置：</li>
</ol>
<p>假设日志分段.log的baseOffset为251，那么相对偏移量relativeOffset = 268 - 251 = 17。</p>
<p>在对应的索引文件.index中找到不大于17的索引项，假设为3, 497，那么根据position为497顺序定位到具体位置。</p>
<hr>
<p>Kafka集群中，一个Broker会被选举为控制器（KafkaController），负责管理集群的所有分区和副本。</p>
<p>每个Broker都会在内存中保存当前KafkaController的BrokerId。</p>
<p>KafkaController选举依赖ZooKeeper，任意时刻，集群中有且仅有一个KafkaController。</p>
<p>每个Broker启动时会尝试读取指定节点的BrokerId，如果值不为-1，说明已有Broker竞选为KafkaController。</p>
<p>如果ZooKeeper中不存在该节点，那么尝试创建该临时（EPHEMERAL）节点，只有创建成功的Broker才成为KafkaController。</p>
<p>如果KafkaController与ZooKeeper断开连接，临时节点就会消失。</p>
<p>集群中的其他Broker节点收到watch对象的下线通知后，都会尝试成为新的KafkaController。</p>
<p>ZooKeeper还有一个与Controller有关的持久（PERSISTENT）节点，存放Controller Epoch。</p>
<p>用于记录Controller变更的次数，即当前的Controller是第几代，称为“控制器的纪元”。</p>
<p>所有和Controller交互的请求都会携带Controller Epoch，如果请求的值小于内存中的值，则认为这个请求无效。</p>
<p>如果请求的值大于内存中的值，说明己经有新的Controller当选了。</p>
<p>当Controller节点的数据发生变化时，每个Broker都更新内存中的Controller的BrokerId。</p>
<p>如果Broker变更前是Controller，变更后自身的BrokerId与新的Controller的BrokerId不一致，那么就需要退位，注销相应的监听器等。</p>
<p>Controller由于异常而下线，造成该临时节点自动删除，当Controller节点被删除时，每个Broker都进行选举。</p>
<p>每台Broker上线时，都会与ZK建立会话，并在指定路径下注册一个临时节点，包含这个Broker的信息。</p>
<p>Controller监听指定路径下的所有子节点，如果有新节点，说明有新Broker上线，如果有节点消失，说明有Broker下线或宕机。</p>
<p>Kafka利用ZK的Watch机制及临时节点的特性来完成集群Broker的上下线管理。</p>
<hr>
<p>当某个分区的Leader副本出现故障时，由Controller为该分区选举新的Leader副本。</p>
<p>当检测到某个分区的ISR集合发生变化时，由Controller通知所有Broker更新其元数据信息。</p>
<p>当为某个Topic增加分区数量时，还是由Controller负责分区的重新分配。</p>
<p>Controller会在ZooKeeper的指定路径注册Handler，处理对应的事件。</p>
<ul>
<li><p>监听Topic相关的变化：Topic增减。</p>
</li>
<li><p>监听分区相关的变化：分区重分配，ISR集合变更，优先副本的选举。</p>
</li>
<li><p>监听Broker相关的变化：Broker上下线，集群的元数据。</p>
</li>
</ul>
<p>Controller：</p>
<ul>
<li>UpdateMetadataRequest：</li>
</ul>
<p>Controller保存了最全的集群元数据，所有Broker定期接收Controller发来的元数据更新请求，更新其内存中的数据。</p>
<p>一旦Topic分区状态变更，Controller将广播UpdateMetadataRequest给所有Broker。</p>
<ul>
<li>CreateTopics：</li>
</ul>
<p>创建Topic请求。</p>
<p>在Zookeeper的指定目录下创建节点，Controller会监听变更，执行创建逻辑。</p>
<ul>
<li>DeleteTopics：</li>
</ul>
<p>删除Topic请求。</p>
<p>和CreateTopics类似。</p>
<ul>
<li>分区重分配：</li>
</ul>
<p>在Zookeeper的指定目录下创建节点，Controller会监听变更，按照方案分配分区。</p>
<ul>
<li>优先Leader分配：</li>
</ul>
<p>优先Leader选举可以自动触发和脚本触发。</p>
<p>在Zookeeper的指定目录下创建节点写入数据，Controller会监听变更，按照方案分配Leader。</p>
<ul>
<li>分区扩展：</li>
</ul>
<p>即增加Topic分区数。</p>
<p>脚本在Zookeeper的指定目录下写入数据，Controller会自动选出Leader并增加分区。</p>
<ul>
<li>新增和下线Broker：</li>
</ul>
<p>如果Controller接收到Broker下线的通知，那么这个Broker管理的分区需要新的Leader。</p>
<p>Controller会遍历每个分区，确定谁作为新的Leader，然后广播新Leader的信息。</p>
<hr>
<p>Controller保存了大量的Kafka集群信息，包括：</p>
<ul>
<li><p>Broker的信息：Broker的所有分区，Broker的所有分区副本，Broker的状态。</p>
</li>
<li><p>Topic的信息：包括Topic的分区信息，Leader副本信息，ISR集合信息。</p>
</li>
</ul>
<p>这些信息在ZooKeeper中也保存了一份。</p>
<p>Controller初始化时，会从ZooKeeper上读取对应的元数据并加载到自己的内存。</p>
<hr>
<p>创建Topic：</p>
<p>在Zookeeper的指定目录下创建对应Topic的持久化节点，并写入分配方案。</p>
<p>Controller监听指定目录下是否有节点变化，如果有，根据其节点中的数据创建对应的副本。</p>
<p>对于Topic的删、改、查等都可以通过这种方法实现。</p>
<hr>
<p>Broker不保存Consumer的状态，从这个角度来说，Broker是无状态的。</p>
<p>实际上Broker是有状态的。</p>
<p>每台Broker在内存中都维护了集群上所有节点和Topic分区的状态信息，即元数据缓存。</p>
<p>Kafka通过Controller发送更新元数据请求，异步维护一致性。</p>
<p>Broker接收到请求便清空当前所有缓存信息，使用UpdateMetadata请求中的数据全量更新。</p>
<hr>
<p>ZooKeeper中共有3个角色：Leader、Follower和Observer。</p>
<p>同一时刻ZooKeeper集群中只有一个Leader，其他的都是Follower和Observer。</p>
<p>Observer不参与投票，默认情况下ZooKeeper中只有Leader和Follower两个角色。</p>
<p>旧版本Kafka：</p>
<p>羊群效应（Herd Effect）：ZooKeeper中一个被监听的节点变化，大量的Watcher通知被发送到客户端，导致在通知期间的其他操作延迟。</p>
<p>脑裂问题（Split Brain）：Consumer再均衡时，每个Consumer都与ZooKeeper通信，可能同一时刻各个Consumer获取的状态不一致。</p>
<hr>
<ul>
<li><p>Topic的分区分配：分配分区副本，即在哪个Broker中创建哪些分区的副本。</p>
</li>
<li><p>Producer的分区分配：为消息指定其所要发往的分区。</p>
</li>
<li><p>Consumer的分区分配：为Consumer指定其可以消费消息的分区。</p>
</li>
</ul>
<hr>
<p>Consumer分区分配策略：</p>
<ul>
<li>RangeAssignor</li>
</ul>
<p>默认分配策略，对每个Topic进行独立的分区分配。</p>
<p>对于每个Topic，把分区按分区ID排序，然后订阅这个Topic的消费组的Consumer再排序，之后将分区分配给Consumer。</p>
<p>假如某个Topic下有四个分区P0、P1、P2、P3。</p>
<p>假如有两个Consumer，C0、C1订阅，那么，分区数量 / 消费者数量，即4 / 2 = 2。</p>
<p>每个Consumer分到2个分区，于是P0、P1分配给C0，P2、P3分配给C1。</p>
<p>假如有三个Consumer，C0、C1、C2订阅，那么，分区数量 / 消费者数量，即4 / 3 = 1。</p>
<p>每个Consumer分到1个分区，还剩一个分给第一个Consumer，于是P0、P1分配给C0，P2分配给C1，P3分配给C2。</p>
<p>假设有五个Consumer订阅，那么最后一个Consumer不会被分配到分区。</p>
<p>如果不够平均分配，那么靠前的Consumer会被多分配一个分区。</p>
<p>缺陷：随着Consumer订阅的Topic数量增加，不均衡会越来越严重。</p>
<ul>
<li>RoundRobinAssignor</li>
</ul>
<p>RangeAssignor是针对单个Topic的分区进行排序分配的。</p>
<p>RoundRobinAssignor将消费组内订阅的所有Topic的分区及所有Consumer排序后分配。</p>
<p>如果消费组内，每个Consumer都订阅了相同的Topic，那么分配结果是均衡的。</p>
<p>如果订阅的Topic列表不同，那么不保证均衡，因为某些Consumer不参与一些Topic的分配。</p>
<p>假设有两个Topic，每个Topic有四个分区，T0P0、T0P1、T0P2、T0P3、T1P0、T1P1、T1P2、T1P3。</p>
<p>假设有三个Consumer，C0、C1、C2订阅，那么轮询分配，C0会分配到T0P0、T0P3、T1P2，C1会分配到T0P1、T1P0、T1P3，C2会分配到T0P2、T1P1。</p>
<hr>
<p>Producer是线程安全的，可以在多个线程中共享Producer实例，也可以将Producer实例池化供线程调用。</p>
<p>消息需要经过拦截器（Interceptor）、序列化器（Serializer）和分区器（Partitioner）后才被发往Broker。</p>
<p>Producer和Consumer都有拦截器。</p>
<p>发送消息主要有三种模式：发后即忘（fire-and-forget）、同步（sync）及异步（async）。</p>
<p>Producer由两个线程协调运行，分别为主线程和Sender线程。</p>
<p>主线程中创建消息，通过拦截器、序列化器和分区器后缓存到消息累加器（RecordAccumulator）中。</p>
<p>Sender线程从RecordAccumulator中获取消息并发送到Broker。</p>
<p>RecordAccumulator主要用来缓存消息以便批量发送。</p>
<p>请求在从Sender线程发往Broker前，会缓存到InFlightRequests，表示已发出去但还没有收到响应的请求。</p>
<p>可以用来判断对应的Node节点负载较大或网络连接有问题。</p>
<p>InFlightRequests还可以获得leastLoadedNode，即负载最小的Node，未确认的请求越多则负载越大。</p>
<p>默认的分区器会根据key的哈希值来计算分区号，如果key为null，那么以轮询的方式发往Topic内的各个可用分区。</p>
<p>不改变Topic分区数量时，key与分区之间的映射保持不变。</p>
<p>Producer一般会发生两种类型的异常：可重试的异常和不可重试的异常。</p>
<p>可重试异常可以通过重试解决，如NetworkException等。</p>
<p>不可重试的异常，如RecordTooLargeException，所发送的消息太大，Producer不会重试，直接抛出异常。</p>
<p>对于可重试的异常，如果配置了retries参数，只要在重试次数内恢复了，就不会抛出异常。</p>
<p>retries参数的默认值为0，默认不重试。</p>
<p>Producer将消息追加到指定Topic的某个分区的Leader副本前，需要知道Topic的分区数量，得出目标分区，然后获得目标分区的Leader副本所在的Broker节点，这都属于元数据。</p>
<p>bootstrap.servers只需要配置部分Broker节点的地址，客户端可以自己发现其他Broker节点。</p>
<p>分区数量及Leader副本的分布都会动态变化，客户端也需要动态地更新。</p>
<hr>
<p>生产者参数：</p>
<ul>
<li>acks：必须有多少个副本收到这条消息，才认为这条消息成功写入，权衡可靠性和吞吐量。</li>
</ul>
<ol>
<li>acks = 1</li>
</ol>
<p>默认值，只要分区的Leader副本成功写入，就收到Broker的成功响应。</p>
<ol start="2">
<li>acks = 0</li>
</ol>
<p>发送消息之后不需要等待任何响应。</p>
<ol start="3">
<li>acks = -1 / acks = all</li>
</ol>
<p>消息发送后，需要等待ISR中的所有副本都成功写入后才能够收到成功响应。</p>
<p>但不一定可靠，因为ISR中可能只有Leader副本，需要配合min.insync.replicas（默认为1）。</p>
<p>min.insync.replicas指定了ISR集合中最小的副本数，不满足就会抛出异常。</p>
<ul>
<li>retries：重试的次数，默认值为0，即在发生异常时不进行重试。</li>
</ul>
<p>如果acks为非零值，并且max.inflight.requests.per.connection大于1，那么可能错序。</p>
<p>如果第一批消息写入失败，第二批消息写入成功，那么Producer重发第一批的消息。</p>
<p>如果重发的消息写入成功，那么就出现了错序。</p>
<hr>
<p>消息中间件一般有两种投递模式：点对点（P2P, Point to Point）和发布／订阅（Pub/Sub）。</p>
<p>点对点基于Queue，Producer发送消息到Queue，Consumer从Queue中接收消息。</p>
<p>发布订阅基于Topic，发布者将消息发布到Topic，消息订阅者从Topic中订阅消息。</p>
<p>Kafka基于Consumer和ConsumerGroup，同时支持两种消息投递模式。</p>
<p>一条消息会被多个ConsumerGroup消费，每个ConsumerGroup只有一个Consumer，实现了广播。</p>
<p>一个ConsumerGroup有多个Consumer，一条消息只被这个ConsumerGroup的一个Consumer消费，实现了单播。</p>
<p>每个Consumer只属于一个ConsumerGroup。</p>
<hr>
<p>Consumer使用拉（Pull）模式，主动向服务端发起请求拉取消息，消息消费是一个轮询的过程。</p>
<p>消费位移可以保存在ZooKeeper或内部Topic中，默认内部Topic。</p>
<p>消费位移持久化称为提交，位移提交的时机可能造成重复消费和消息丢失。</p>
<p>假设当前拉取的消息集为[x + 2, x + 7]，x + 2是上次提交的消费位移，说明己经完成了x + 2之前的消息消费，假设当前正在处理的位置为x + 5。</p>
<p>如果拉取消息后就提交位移，那么当前消费x + 5时宕机，恢复后，重新拉取的消息从 x + 8 开始的，丢失了消息。</p>
<p>如果位移提交在消费完所有拉取到的消息后，那么当前消费x + 5时宕机，恢复后，重新拉取的消息是从 x + 2 开始的，发生了重复消费。</p>
<p>Kafka默认自动提交，这个自动提交不是每消费一条消息就提交一次，而是定时提交。</p>
<p>Consumer每隔5秒将拉取到的每个分区中最大的消息位移进行提交。</p>
<p>每次向服务端发起拉取请求前会检查是否可以提交，提交上次轮询的位移。</p>
<p>自动提交消费位移可能导致重复消费和消息丢失。</p>
<p>假设刚提交完一次消费位移，然后拉取一批消息，在下次自动提交前，Consumer崩溃了，又从上次提交的地方重新消费，发生了重复消费（同样适用再均衡）。</p>
<p>假设拉取线程不断地拉取消息并存入本地缓存，另一个处理线程从缓存中读取消息并处理。</p>
<p>假设进行到了第x + 1次拉取，并提交第x次拉取的位移，但处理线程还在处理第x次拉取的消息。</p>
<p>如果此时处理线程发生了异常，恢复后会跳过第x次拉取的消息，发生了消息丢失。</p>
<p>手动提交可以分为同步提交和异步提交。</p>
<hr>
<p>Consumer也具备容灾能力。</p>
<p>再均衡指分区的所属权从一个Consumer转移到另一Consumer。</p>
<p>再均衡期间，消费组内的Consumer不可用，无法消费消息，类似GC的Stop The World。</p>
<p>当分区被重新分配给另一个Consumer时，Consumer当前的状态也会丢失。</p>
<p>Consumer消费完某个分区中的一部分消息时还没有提交消费位移就发生了再均衡，分区被分配给另一个Consumer，被消费的消息又被重新消费。</p>
<hr>
<p>KatkaProducer是线程安全的，KafkaConsumer是非线程安全的。</p>
<p>KafkaConsumer检测当前是否只有一个线程在操作，若有其他线程正在操作则抛出异常。</p>
<p>检测方法和通常的锁不同，不会阻塞，它仅通过计数标记来检测是否发生了并发操作。</p>
<hr>
<p>如下几种情形会触发再均衡：</p>
<ul>
<li><p>有新的Consumer加入消费组。</p>
</li>
<li><p>有Consumer下线（如长时间GC或网络延迟导致GroupCoordinator未收到心跳）。</p>
</li>
<li><p>有Consumer主动退出消费组（如取消对Topic的订阅）。</p>
</li>
<li><p>消费组对应的GroupCoorinator节点发生了变更。</p>
</li>
<li><p>消费组订阅的Topic或Topic的分区数量发生了变化。</p>
</li>
</ul>
<hr>
<ul>
<li>FIND COORDINATOR</li>
</ul>
<p>Consumer需要确定所属的ConsumerGroup对应的GroupCoordinator的Broker。</p>
<p>如果没有缓存没有，需要向集群中的某个节点发送FindCoordinatorRequest，查找对应的GroupCoordinator。</p>
<p>每个ConsumerGroup会分配一个Brokers作为消费组的协调者，负责管理ConsumerGroup的状态。</p>
<p>包括Consumer的上下线，Topic的分区变化，协调分区的分配（消费组的再均衡）。</p>
<ul>
<li>JOIN GROUP</li>
</ul>
<p>找到ConsumerGroup对应的GroupCoordinator后，需要加入ConsumerGroup。</p>
<p>Consumer与GroupCoordinator保持心跳连接，当有新的Consumer申请加入（JoinGroupRequest）时，通过心跳响应通知Consumer，于是其他Consumer发起JoinGroupRequest，重新执行平衡。</p>
<p>Consumer向GroupCoordinator发送JoinGroupRequest，并阻塞等待响应。</p>
<p>如果ConsumerGroup内还没有Leader，那么第一个加入的Consumer成为LeaderConsumer。</p>
<p>如果LeaderConsumer退出了ConsumerGroup，那么重新选举（其实是随机指定）。</p>
<p>JoinGroupRequest包含了该Consumer订阅的Topic，及支持的分配策略等信息。</p>
<p>GroupCoordinator根据各个Consumer上报的信息，选出被支持最多的分区分配策略，作为当前ConsumerGroup的分配策略。</p>
<p>GroupCoordinator收集了全部Consumer的JoinGroupRequest后，回复各个Consumer，但只有给LeaderConsumer的响应中包含成员的有效数据。</p>
<ul>
<li>SYNC GROUP</li>
</ul>
<p>LeaderConsumer根据分区分配策略和其它成员Consumer的订阅信息，实施具体的分区分配。</p>
<p>LeaderConsumer不直接和其余的Consumer同步，而是通过GroupCoordinator转发。</p>
<p>ConsumerGroup内所有的Consumer都会发送SyncGroupRequest，请求同步分配方案，但只有LeaderConsumer的请求包含内容。</p>
<p>GroupCoordinator根据LeaderConsumer的分配方案，连同ConsumerGroup的元数据一起存入ConsumerOffsetsTopic，最后响应给各个Consumer。</p>
<ul>
<li>HEARTBEAT</li>
</ul>
<p>消费消息之前，Consumer需要确定拉取消息的起始位置。</p>
<p>Consumer发送OffsetFetchRequest，获取上次提交的消费位移，继续消费。</p>
<p>Consumer通过向GroupCoordinator发送心跳维持与ConsumerGroup的从属，以及对分区的所有权。</p>
<hr>
<p>事件驱动（Reactor模式）：</p>
<ul>
<li>一个Acceptor线程：</li>
</ul>
<p>一个Selector，关心ServerSocketChannel的OP_ACCEPT事件，监听新的Socket连接请求。</p>
<p>将SocketChannel按RoundRobin方式交给对应的Processor线程处理。</p>
<ul>
<li>N个Processor线程：</li>
</ul>
<p>每个Processor都有自己的Selector，关心SocketChannel的OP_READ和OP_WRITE事件，处理网络读写。</p>
<p>从SocketChannel读取数据，将响应返回给SocketChannel，不参与业务逻辑。</p>
<p>多个Selector可以缓解大量IO事件导致的分发瓶颈。</p>
<ul>
<li>M个RequestHandler线程：</li>
</ul>
<p>处理Request，调用KafkaApis处理，并将Response返回给Processor线程，处理业务IO。</p>
<ul>
<li>一个RequestChannel：</li>
</ul>
<p>Processor和RequestHandler交换数据的地方，用于解耦。</p>
<p>包含一个RequestQueue，Processor放入Request，RequestHandler取出Request处理。</p>
<p>包含N个ResponseQueue，对应N个Processor，RequestHandler将处理完的Response放入，Processor取出处理。</p>
<hr>
<p>创建ServerSocketChannel，在Selector上注册OP_ACCEPT事件，Selector监听ServerSocketChannel指定端口的连接请求。</p>
<p>客户端发起连接，OP_ACCEPT事件就绪，Acceptor处理，为这个连接创建SocketChannel，设置为非阻塞模式。</p>
<p>Acceptor线程以轮询的方式把SocketChannel转交给对应的Processor线程。</p>
<p>Processor线程在Selector上注册这个SocketChannel的OP_READ事件，每个Processor都有一个Selector，非阻塞地处理多个SocketChannel的读写。</p>
<p>Processor线程不断轮询Selector，某个SocketChannel可读事件就绪时，Processor线程生成Request，加入RequestChannel的RequestQueue。</p>
<p>RequestHandler线程从中取出Request，处理后将Response放入对应的ResponseQueue，Processor线程取出响应，当对应的SocketChannel的OP_WRITE事件就绪时，写到SocketChannel。</p>
<p>上面略过了缓冲和选择键的处理，从响应队列中取出响应时，如果对应的SocketChannel的OP_WRITE事件未就绪，那岂不是会阻塞？</p>
<p>应该是直接写到缓冲就返回，就绪时再把缓冲的数据写到SocketChannel。</p>
<hr>
<p>Kafka的延时操作，如延时生产、延时拉取和延时删除等。</p>
<p>Leader副本等待ISR集合中的所有副本都确认后，才回复响应。</p>
<p>延时操作不同于定时操作，定时是指在特定时间之后执行，而延时可以在超时之前完成，所以支持外部事件触发。</p>
<p>延时生产的外部事件是所要写入消息的某个分区的HW（高水位）发生增长。</p>
<p>Follower副本己经拉取了Leader副本的最新位置，又向Leader副本发送拉取请求，而Leader副本没有新消息写入。</p>
<p>Leader副本先读取日志文件，如果消息不够，那么创建一个延时拉取操作，等待足够数量的消息。</p>
<ul>
<li>DelayQueue：</li>
</ul>
<p>延迟队列，元素必须实现Delayed接口。</p>
<p>是一个PriorityQueue优先队列，只是个容器，需要其他线程获取和执行任务。</p>
<p>读取DelayQueue队头只需要O(1)的时间复杂度（但是获取后移除需要O(logn)的复杂度）。</p>
<ul>
<li>Timer：</li>
</ul>
<p>核心是一个优先队列（最小二叉堆）和一个任务线程。</p>
<p>最早需要执行的任务在优先队列的第一个，插入和删除的时间复杂度都是O(logn)。</p>
<p>只有一个执行线程，不断拿第一个任务的执行时间和当前时间对比。</p>
<p>如果时间已到，并且任务是周期性任务，那么修改当前任务时间为下次执行的时间，否则将任务从优先队列中移除，最后执行任务。</p>
<p>如果时间未到，则阻塞等待。</p>
<p>当数据量大的时候，入堆出堆操作性能不好。</p>
<p>单线程执行，如果一个任务执行的时间过久会影响下一个任务的执行。</p>
<p>没有处理异常，一个任务抛异常会导致之后的任务都无法执行。</p>
<ul>
<li>ScheduledThreadPoolExecutor：</li>
</ul>
<p>多线程版的Timer，并且对异常做了处理。</p>
<ul>
<li>TimingWheel</li>
</ul>
<p>环形数组实现，槽的内部用双向链表保存任务，添加和删除的链表操作时间复杂度都是O(1)，适合任务数很大的场景。</p>
<p>如果1s扫一个槽，那么这个时间轮的精度就是1s。</p>
<p>此时，延迟1.2s和1.5s的任务会被加入到同一个槽，然后在1秒的时候遍历这个槽的链表执行任务。</p>
<p>假如共有8个槽0~7，假设槽的时间单位为1s，要加入一个延时5s的任务，就是 5 % 8 + 1 = 6，即放在第6个槽位，下标为5。</p>
<p>每秒指针移动一槽，遍历这槽中的双向链表执行任务。</p>
<p>假设要加入一个50s后执行的任务，常见有两种方式。</p>
<p>一种是增加轮次的概念，如Netty的HashedWheelTimer。</p>
<p>50 % 8 + 1 = 3，即放在第3个槽位，下标为2。</p>
<p>(50 - 1) / 8 = 6，即当循环6轮之后扫到下标2的槽位会触发这个任务。</p>
<p>一种是通过多层次的时间轮，如时钟，以及Kafka的时间轮算法。</p>
<p>第一层走了一圈，第二层就走一格，那么这里第二层的一格就是8s。</p>
<p>假设第二层也是8个槽，那么第二层走一圈，第三层走一格，那么这里第三层一格就是64s。</p>
<p>假设第三层也是8个槽，那么时间轮可以处理最多延迟512s的任务。</p>
<p>为了保证时间精度一致性，多层次时间轮还有降级操作。</p>
<p>假设一个任务延迟500s执行，刚开始是在第三层，过了436s后，还要64s就会触发，此时它就是个延迟64s的任务，会被降到第二层。</p>
<p>再过56s，它就是个延迟8s执行的任务，它会再被降级放在第一层，等待执行。</p>
<p>Kafka按需创建时间轮，如果任务超出了时间轮的范围，那么再创建一个更高一级的时间轮，以此类推。</p>
<p>如果每秒定时推进，假如第一个任务还有200s执行，那么有199次属于空推进。</p>
<p>Kafka对时间轮每个槽都维护一个到期时间，将槽，而不是任务，放入DelayQueue，按到期时间排序，进行时间推进。</p>
<p>空间换时间，解决空推进，每次推进都把能降级的任务重新插入降级。</p>
<p>DelayQueue的插入和删除的时间复杂度为O(logn)，TimingWheel可以将插入和删除的时间复杂度降为O(1)。</p>
<p>用TimingWheel做任务添加和删除操作，用DelayQueue做时间推进工作。</p>
<hr>
<p>Kafka中的选举：</p>
<ul>
<li>控制器的选举</li>
</ul>
<p>KafkaController的选举依赖Zookeeper。</p>
<p>KafkaController负责管理整个集群中所有分区和副本的状态，负责选举Leader副本。</p>
<p>检测到某个分区的ISR集合发生变化时，通知所有Broker更新元数据。</p>
<ul>
<li>Leader副本的选举</li>
</ul>
<p>分区Leader副本的选举由KafkaController负责。</p>
<p>当创建分区（创建Topic或增加分区）或分区上线（Leader副本下线，此时需要选举一个新的Leader上线）时都要执行Leader选举。</p>
<p>基本思路是按照AR集合中副本的顺序查找第一个存活的副本，并且这个副本在ISR集合中。</p>
<p>这里是根据AR的顺序而不是ISR的顺序。</p>
<p>分区的AR集合在分配的时候就被指定，只要不发生重分配，集合内部副本的顺序是不变的，而分区的ISR集合中副本的顺序可能会改变。</p>
<p>分区重分配时也需要执行Leader选举。</p>
<p>也是从重分配的AR列表中找到第一个存活的副本，且这个副本在目前的ISR列表中。</p>
<ul>
<li>Consumer相关的选举</li>
</ul>
<p>略。</p>
<hr>
<p>MQ的消息传输保障有3个层级。</p>
<ul>
<li><p>at most once：至多一次。消息可能丢失，但不会重复传输。</p>
</li>
<li><p>at least once：最少一次。消息不会丢失，但可能重复传输。</p>
</li>
<li><p>exactly once：恰好一次。消息不会丢失，不会重复传输。</p>
</li>
</ul>
<p>Producer发送消息时，一旦消息被成功提交，由于多副本，消息不会丢失。</p>
<p>Producer发送消息时遇到网络问题，无法判断消息是否己经提交，但可以重试，是at least once。</p>
<p>Consumer根据处理消息和提交消费位移的顺序，可能是at least once或at most once。</p>
<p>Kafka引入了幂等和事务，以此实现exactly once。</p>
<p>幂等，就是对接口的多次调用的结果和调用一次是一致的，避免Producer在重试时重复写入消息。</p>
<p>幂等默认关闭，需要Producer开启。</p>
<p>为了实现Producer幂等，Kafka引入了生产者ID（PID）和序列号（SN）两个概念。</p>
<p>Producer实例在初始化时都会分配一个PID。</p>
<p>对于每个PID，消息发送到的每一个分区都有对应的单调递增序列号＜PID，分区＞。</p>
<p>Broker在内存中为每一对＜PID，分区＞维护一个序列号。</p>
<p>Broker会验证SN是否连续，不允许跳过，同时忽略之前的SN。</p>
<p>TransactionCoordinator管理PID信息，新建或本地PID段用完时，向ZooKeeper申请PID段。</p>
<p>Broker向ZooKeeper申请PID段后，会把PID段信息写入节点，当其他Broker申请时，先读此节点，最后把信息写回。</p>
<p>幂等不能跨多个分区，事务可以弥补这个缺陷。</p>
<p>事务可以保证Producer对多个分区写入的原子性（要么全部成功，要么全部失败）。</p>
<p>跨会话的幂等写入：即使中间故障，恢复后依然可以保持幂等性。</p>
<p>跨会话的事务恢复：如果Producer挂了，启动的下个Producer依然可以保证上一个事务完成（提交或终止）。</p>
<p>从Consumer的角度，事务不能保证己提交的事务中的所有消息都能被消费（可能没分配到事务的分区）。</p>
<p>Consumer可以设置隔离级别，默认为“read uncommitted”，可以消费到未提交的事务。</p>
<p>可以设置为“read committed”，在提交事务前，Consumer不可见。</p>
<p>不过Consumer会缓存这些消息，直到Producer提交事务后才能消费。</p>
<p>如果Producer终止事务，那么将这些缓存的消息丢弃。</p>
<p>日志文件中除了普通消息，还有一种控制消息（ControlBatch）专门标志一个事务的结束。</p>
<p>控制消息共有两种类型：COMMIT和ABORT。</p>
<p>Consumer通过控制消息来判断对应的事务是被提交了还是被中止了，然后结合隔离级别处理。</p>
<p>为了实现事务，Kafka引入了事务协调器（TransactionCoordinator），类比一下组协调器（GroupCoordinator）。</p>
<p>Producer会被指派一个TransactionCoordinator，所有的事务逻辑包括分派PID等都由TransactionCoordinator负责。</p>
<p>TransactionCoordinator和2PC协议中协调者不太一样，主要为了管理事务相关的状态信息。</p>
<p>TransactionCoordinator会将事务状态持久化到内部Topic中。</p>
<p>如果一个事务的TransactionCoordinator宕机，需要转移到其他的机器。</p>
<p>事务状态信息恢复时从内部Topic恢复，容错性是多副本机制，一致性是min.isr + ack机制；</p>
<p>Producer在宕机恢复后能主动终止上次未完成的事务。</p>
<p>幂等性引入的PID无法解决，因为每次Producer重启PID都会更新，于是Producer端引入了TransactionalId。</p>
<p>事务要求Producer开启幕等性，同时用户必须显式设置唯一的TransactionalId。</p>
<p>TransactionalId标识一个事务操作，这个事务的所有操作都在一个TransactionCoordinator处理。</p>
<p>为了保证新的Producer启动后具有相同TransactionalId的旧Producer立即失效，每个Producer通过TransactionalId获取PID的同时，还会获取一个单调递增的ProducerEpoch。</p>
<p>LSO指LastStableOffset，与Kafka事务有关。</p>
<p>开启Kafka事务，Producer发送了若干消息，如果没有提交事务，那么第一条消息的位置为firstUnstableOffset。</p>
<p>对未完成的事务，LSO的值等于事务中第一条消息的位置，对已完成的事务，和HW相同，LSO ≤ HW ≤ LEO。</p>
<p>LSO会影响Kafka消费滞后量（Kafka Lag，消息堆积量）的计算。</p>
<p>分区的Lag = HW – ConsumerOffset，其中ConsumerOffset表示当前的消费位移。</p>
<p>如果消息引入了事务，并且Consumer配置为“read_committed”，Lag = LSO – ConsumerOffset。</p>
<p>Kafka有两个内部Topic，分别保存Consumer的位移信息和事务日志消息。</p>
<hr>
<p>高性能实现：</p>
<ol>
<li><p>顺序写盘；</p>
</li>
<li><p>页缓存，预读；</p>
</li>
<li><p>零拷贝，对消息的读写都基于FileChannel；</p>
</li>
<li><p>mmap，文件内存映射，对索引文件的读写基于MappedBuffer；</p>
</li>
<li><p>消息批处理；</p>
</li>
<li><p>批量压缩；</p>
</li>
<li><p>分区并行发送和消费；</p>
</li>
</ol>
<hr>
<p>高可用实现：</p>
<ol>
<li><p>多副本；</p>
</li>
<li><p>自动选主；</p>
</li>
</ol>
<hr>
<p>高可靠实现：</p>
<ol>
<li><p>request.required.acks = all：保证ISR集合中所有副本都成功写入（默认1，只保证Leader副本成功写入）；</p>
</li>
<li><p>replication.factor &gt; 1：保证必须存在Follower副本；</p>
</li>
<li><p>min.insync.replicas &gt; 1：保证ISR集合中必须存在Follower副本。</p>
</li>
<li><p>同步（默认）的发送模式，不会丢失数据。</p>
<ul>
<li><p>发送到Leader，ISR全部同步后，Leader宕机，会选举出新的Leader，数据不会丢失。</p>
</li>
<li><p>发送到Leader，部分ISR同步后，Leader宕机，Producer端返回异常，如果重发消息，可能重复。</p>
</li>
</ul>
</li>
<li><p>消费端手动提交位移，如果消息没被消费，不能提交对应的位移。</p>
</li>
</ol>
<hr>
<p>原书作者提供的一些面试题：</p>
<ul>
<li><p>Kafka的用途有哪些？使用场景如何？</p>
</li>
<li><p>Kafka中的ISR、AR又代表什么？ISR的伸缩又指什么？</p>
</li>
<li><p>Kafka中的HW、LEO、LSO、LW等分别代表什么？</p>
</li>
<li><p>Kafka中是怎么体现消息顺序性的？</p>
</li>
<li><p>Kafka中的分区器、序列化器、拦截器？它们之间的处理顺序是什么？</p>
</li>
<li><p>KafkaProducer客户端的整体结构是什么样子的？</p>
</li>
<li><p>KafkaProducer客户端中使用了几个线程来处理？分别是什么？</p>
</li>
<li><p>Kafka的旧版Scala的Consumer客户端的设计有什么缺陷？</p>
</li>
<li><p>有哪些情形会造成重复消费？</p>
</li>
<li><p>那些情景下会造成消息漏消费？</p>
</li>
<li><p>KafkaConsumer是非线程安全的，那么怎么样实现多线程消费？</p>
</li>
<li><p>Consumer与消费组之间的关系？</p>
</li>
<li><p>使用kafka-topics.sh创建（删除）了一个Topic之后，Kafka背后会执行什么逻辑？</p>
</li>
<li><p>Topic的分区数可不可以增加？如果可以怎么增加？如果不可以，为什么？</p>
</li>
<li><p>Topic的分区数可不可以减少？如果可以怎么减少？如果不可以，为什么？</p>
</li>
<li><p>创建Topic时如何选择合适的分区数？</p>
</li>
<li><p>Kafka目前有那些内部Topic，各自作用又是什么？</p>
</li>
<li><p>优先副本是什么？它有什么特殊的作用？</p>
</li>
<li><p>Kafka有哪几处地方有分区分配的概念？大致的过程及原理?</p>
</li>
<li><p>Kafka的日志目录结构?</p>
</li>
<li><p>Kafka中有那些索引文件？</p>
</li>
<li><p>指定一个offset，Kafka怎么查找对应的消息？</p>
</li>
<li><p>指定一个timestamp，Kafka怎么查找对应的消息？</p>
</li>
<li><p>对Kafka的Log Retention的理解？</p>
</li>
<li><p>对Kafka的Log Compaction的理解？</p>
</li>
<li><p>对Kafka底层存储的理解（页缓存、内核层、块层、设备层）？</p>
</li>
<li><p>Kafka的延时操作的原理？</p>
</li>
<li><p>Kafka控制器的作用？</p>
</li>
<li><p>消费再均衡的原理是什么？（Consumer协调器和消费组协调器）</p>
</li>
<li><p>Kafka中的幂等是怎么实现的？</p>
</li>
<li><p>Kafka中的事务是怎么实现的？</p>
</li>
<li><p>Kafka中有那些地方需要选举？选举策略又有哪些？</p>
</li>
<li><p>失效副本是指什么？有那些应对措施？</p>
</li>
<li><p>多副本下，各个副本中的HW和LEO的演变过程？</p>
</li>
<li><p>为什么Kafka不支持读写分离？</p>
</li>
<li><p>Kafka在可靠性方面做了哪些改进？（HW, LeaderEpoch）</p>
</li>
<li><p>Kafka中怎么实现死信队列和重试队列？</p>
</li>
<li><p>Kafka中的延迟队列怎么实现？</p>
</li>
<li><p>Kafka中怎么做消息审计？</p>
</li>
<li><p>Kafka中怎么做消息轨迹？</p>
</li>
<li><p>Kafka中有那些配置参数比较有意思？</p>
</li>
<li><p>Kafka有哪些指标需要着重关注？</p>
</li>
<li><p>怎么计算Lag？(注意隔离级别的不同)</p>
</li>
<li><p>Kafka的那些设计让它有如此高的性能？</p>
</li>
<li><p>Kafka有什么优缺点？</p>
</li>
<li><p>为什么选择Kafka?</p>
</li>
<li><p>怎么确保Kafka极大程度上的可靠性？</p>
</li>
</ul>

				</div>
				<!-- about -->
				
			</div>
			<!-- pagination -->
			
			<div class="comment-section">
	
	


</div>
		</div>
		
	</div>


        <footer>
             
<a id="gotop" href="#" title="back to top"><i class="mdi-hardware-keyboard-arrow-up"></i></a>

        </footer>
    </div>
    <!-- <script src="/libs/bs/js/bootstrap.min.js"></script> -->
    <!-- <script src="//apps.bdimg.com/libs/bootstrap/3.3.4/js/bootstrap.min.js"></script> -->
    <script>
        var timeEnd = new Date();
        console.log('耗时：' + (timeEnd - timeStart));
        document.addEventListener('DOMContentLoaded', (event) => {
            document.querySelectorAll('pre').forEach((block) => {
                block.classList.add("line-numbers");
            });
        });
    </script>

    <script src="/js/prism.js"></script>
</body>
</html>
